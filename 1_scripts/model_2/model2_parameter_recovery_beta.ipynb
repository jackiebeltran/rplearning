{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444d1187",
   "metadata": {},
   "source": [
    "this model will operate on two learning rates based on condition and fits beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "530b91d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d292965",
   "metadata": {},
   "source": [
    "### Define environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b369fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    \n",
    "    \"\"\"Class for the RP learning task\n",
    "\n",
    "    Parameters \n",
    "    ----------\n",
    "\n",
    "    n_actions : array, float \n",
    "        choosing the top or bottom stimulus\n",
    "\n",
    "    r_p :\n",
    "        reward probability with 80/20 contingency\n",
    "\n",
    "    p_p :\n",
    "        punishment probability with 80/20 contingency\n",
    "\n",
    "    inv_rp :\n",
    "        inverse reward probability \n",
    "\n",
    "    inv_pp :\n",
    "        inverse punishment probability\n",
    "\n",
    "    best_action : \n",
    "        pre-defined action that's the 'best'\n",
    "        set as a np.random variable that's either 1 or 2 to randomize every time I initialize\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_actions, r_p, p_p, inv_rp, inv_pp, best_action):\n",
    "        \n",
    "        self.n_actions = n_actions # choice of top or bottom stimulus\n",
    "\n",
    "        self.r_p = r_p             # reward prob outcome\n",
    "        self.p_p = p_p             # punishment prob outcome\n",
    "\n",
    "        self.inv_rp = inv_rp       # inverse reward prob\n",
    "        self.inv_pp = inv_pp       # inverse punishment prob\n",
    "\n",
    "        self.best_action = best_action  # predefined best action\n",
    "\n",
    "# Step Function: based on the condition, the environment returns an appropriate reward\n",
    "\n",
    "    \"\"\"\n",
    "    Conditions are set such that 1 = Reward, 2=Punishment, 3=Neutral\n",
    "    The best action is that which is associated with a higher probability of returning reward\n",
    "        - Taking the best action returns a value of 1\n",
    "        - Not taking the best action returns a value of 0 \n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def step(self, action, condition, trial):       # takes in condition  \n",
    "        \n",
    "        if condition == 1:                          ## Reward\n",
    "            if action == self.best_action:                               \n",
    "                reward = self.r_p[trial]            # index through r_p for 80% chance reward\n",
    "                took_best_action = 1                # true, best action was taken \n",
    "            else: \n",
    "                reward = self.inv_rp[trial]         # index through inv_rp for 20% chance reward\n",
    "                took_best_action = 0                # false \n",
    "                \n",
    "        elif condition == 2:                        ## Punishment\n",
    "            if action == self.best_action:\n",
    "                reward = self.p_p[trial]\n",
    "                took_best_action = 1                \n",
    "            else:\n",
    "                reward = self.inv_pp[trial] \n",
    "                took_best_action = 0\n",
    "        else:                                       ## Neutral\n",
    "            reward = 0\n",
    "            took_best_action = 3        \n",
    "\n",
    "        return reward, took_best_action, condition             # return condition agent's in to update "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae111376",
   "metadata": {},
   "source": [
    "### Define agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d66e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "\n",
    "    \"\"\" Class for the agent to operate on a soft max policy when choosing between the two actions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    r_alpha : float, range (0, 1)\n",
    "        reward learning rate \n",
    "    p_alpha : float, range (0, 1)\n",
    "        punishment learning rate\n",
    "    beta : float, range (0, inf) \n",
    "      inverse temperature to control level of stochasticity in the choice\n",
    "      **0 means the agent explores randomly \n",
    "      **large value approaching inf acts more deterministically\n",
    "      \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, r_alpha, p_alpha, beta, q_init= False):\n",
    "\n",
    "        # initialize action space which is an array of all possible actions\n",
    "        self.action_space = np.arange(env.n_actions) # 2 possible actions\n",
    "\n",
    "        # initialize parameters\n",
    "        self.r_alpha = r_alpha\n",
    "        self.p_alpha = p_alpha\n",
    "        self.beta = beta\n",
    "\n",
    "        # initialize Q-values \n",
    "        if q_init: \n",
    "            self.q = q_init # assigns q to those initial values     \n",
    "        else:   \n",
    "            self.q = np.zeros((3, env.n_actions)) # otherwise they are 6 values of 0 (2 stimuli per condition)\n",
    "\n",
    "        # initialize action counter, this counts how many times an action is taken\n",
    "        self.action_counter = np.zeros((env.n_actions, ))\n",
    "        \n",
    "    # Learning policy\n",
    "        \n",
    "    def soft_max_policy(self, condition):        \n",
    "        p = np.exp(self.beta * self.q[condition-1,:]) / (np.exp(self.beta * self.q[condition-1,:])).sum() # prob of choosing an action by condition        \n",
    "        action = np.nonzero(np.random.random((1,)) <= np.cumsum(p))[0][0] + 1               \n",
    "        return action # returns 1 or 2\n",
    "    \n",
    "    # Q-learning update function\n",
    "  \n",
    "    def update(self, condition, action, reward, verbose=False):\n",
    "        if condition == 1: # reward trial\n",
    "            self.action_counter[action-1] = self.action_counter[action-1] + 1        \n",
    "            self.q[condition-1, action-1] = self.q[condition-1, action-1] + self.r_alpha*(reward - self.q[condition-1, action-1]) # update by condition\n",
    "            # print('updated q values for reward trial' + str(self.q)) \n",
    "        elif condition == 2: # punishment trial \n",
    "            self.action_counter[action-1] = self.action_counter[action-1] + 1\n",
    "            self.q[condition-1, action-1] = self.q[condition-1, action-1] + self.p_alpha*(reward - self.q[condition-1, action-1]) # update by condition\n",
    "            # print('updated q values for punishment trial' + str(self.q)) \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48f3a85",
   "metadata": {},
   "source": [
    "### Define simulation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e9807d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RP_simulation(n_timesteps, n_trials_per_block, params, verbose=False):\n",
    "    \n",
    "    \"\"\"Function for running one simulation of the RL model \n",
    "    specifying how the environment and agent interact \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    n_timesteps :\n",
    "        how many timesteps to run the simulation for\n",
    "        \n",
    "    params : dictionary containing parameters of the simulation \n",
    "        \n",
    "        Environment parameters\n",
    "        ----------------------\n",
    "        n_actions: int \n",
    "            number of actions the agent can choose from \n",
    "        r_p : \n",
    "            possible returns from reward condition\n",
    "        p_p : \n",
    "            possible returns from punishment condition\n",
    "        inv_rp :\n",
    "            inverse reward probability\n",
    "        inv_pp :\n",
    "            inverse punishment probability\n",
    "        best_action: int\n",
    "            which is the best action\n",
    "            \n",
    "        Agent parameters\n",
    "        ----------------\n",
    "        r_alpha : \n",
    "            reward learning rate\n",
    "        p_alpha :\n",
    "            punishment learning rate\n",
    "        beta : \n",
    "            inverse temperature\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    sim_output: dictionary containing simulation output\n",
    "\n",
    "        actions: array, int, shape(n_timesteps, )\n",
    "            Action that the agent took on each timestep.\n",
    "\n",
    "        rewards: array, float, shape(n_timesteps, )\n",
    "            Rewards that the agent received on each timestep.\n",
    "\n",
    "        optimal_action: array, boolean, shape(n_timesteps, )\n",
    "            1 is true, 0 is false\n",
    "            \n",
    "        condition: \n",
    "            reward(1), punishment(2), neutral(3)\n",
    "        \n",
    "    \"\"\"\n",
    "    # initialize environment \n",
    "    env = Environment(params['n_actions'], params['r_p'], params['p_p'], params['inv_rp'], params['inv_pp'], params['best_action'])\n",
    "    \n",
    "    # initialize agent\n",
    "    agent = Agent(env, params['r_alpha'], params['p_alpha'], params['beta'])\n",
    "    \n",
    "    # initialize output lists \n",
    "    A = [] # action taken \n",
    "    R = [] # reward taken\n",
    "    OA = [] # was optimal action taken \n",
    "    C = [] # condition\n",
    "    \n",
    "    # Loop through trials\n",
    "    \n",
    "    a = np.tile([1], 30) # reward\n",
    "    b = np.tile([2], 30) # punishment \n",
    "    c = np.tile([3], 30) # neutral\n",
    "    d = np.concatenate([a,b,c])\n",
    "\n",
    "    np.random.shuffle(d) # shuffle order of conditions \n",
    "    e = np.array_split(d,3)\n",
    "        \n",
    "    for i in np.arange(n_timesteps): # 3\n",
    "        for t in np.arange(n_trials_per_block): # 30\n",
    "            \n",
    "            condition = e[i][t]\n",
    "        \n",
    "            # agent takes an action based on soft max policy which now takes in a condition parameter \n",
    "            action = agent.soft_max_policy(condition) \n",
    "            \n",
    "            # environment responds with a reward \n",
    "            reward, took_best_action, condition = env.step(action, condition, t)\n",
    "\n",
    "            # record action, reward, and optimal outcome result\n",
    "            A.append(action)\n",
    "            R.append(reward)\n",
    "            OA.append(took_best_action)\n",
    "            C.append(condition)\n",
    "\n",
    "            # update \n",
    "            agent.update(condition, action, reward)\n",
    "        \n",
    "    sim_output = {\n",
    "        'timestep': np.arange(n_timesteps)+1,\n",
    "        'actions': np.array(A),\n",
    "        'rewards': np.array(R),\n",
    "        'optimal_action': np.array(OA),\n",
    "        'condition': np.array(C)\n",
    "    }\n",
    "        \n",
    "    return env, agent, sim_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b061ebb8",
   "metadata": {},
   "source": [
    "### Parameter Recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70f74f6",
   "metadata": {},
   "source": [
    "##### Define likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f7d4565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T is the number of trials, 90 \n",
    "# L represents the log likelihood for all trials such that as you go through each trial you compute one value and that gets added on\n",
    "\n",
    "def m2_loglikelihood(training_params, r_alpha, p_alpha, actions, rewards, condition):\n",
    "    \n",
    "    beta = training_params\n",
    "\n",
    "    q_value = np.ones((3,2))*0.0 \n",
    "    T = len(actions)\n",
    "    L = 0  \n",
    "    \n",
    "    for t in range(T): \n",
    "        \n",
    "        # compute choice probabilities of picking an action based on soft max \n",
    "        p = np.exp(beta * q_value[condition[t]-1,:]) / (np.exp(beta * q_value[condition[t]-1,:])).sum()\n",
    "\n",
    "        # compute choice probability for actual choice based on the probability computed above by condition \n",
    "        choiceProb = p[actions[t]-1]\n",
    "\n",
    "        # sum of the natural log of each individual choice probability to get the prob of a whole dataset (90 trials)\n",
    "        L += np.log(choiceProb) \n",
    "    \n",
    "        # update values with q learning, index for t and update by condition using the two separate learning rates\n",
    "        if condition[t] == 1:\n",
    "            q_value[condition[t]-1, actions[t]-1] = q_value[condition[t]-1, actions[t]-1] + r_alpha * (rewards[t] - q_value[condition[t]-1, actions[t]-1])\n",
    "        elif condition[t] == 2:\n",
    "            q_value[condition[t]-1, actions[t]-1] = q_value[condition[t]-1, actions[t]-1] + p_alpha * (rewards[t] - q_value[condition[t]-1, actions[t]-1])\n",
    "    \n",
    "    return -L   # this will return a negative log likelihood which is what we want to minimize to perform parameter recovery/fitting on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497cf73a",
   "metadata": {},
   "source": [
    "##### Define fitting function for minimizing likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1de7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Fitting beta\n",
    "This fitting function returns a value for 'fun' which is the -LL & a value for 'x' which is the best fit alpha\n",
    "\n",
    "'''\n",
    "\n",
    "def fit_RP_Learning(r_alpha, p_alpha, actions, rewards, condition):\n",
    "\n",
    "    init_cond = np.array([np.random.randint(1,50)])    \n",
    "    bnds = [(1,50)]\n",
    "    optimum_output = minimize(m2_loglikelihood, init_cond, args=(r_alpha, p_alpha, actions, rewards, condition), method='L-BFGS-B', bounds=bnds)\n",
    "     \n",
    "    return optimum_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf120f7c",
   "metadata": {},
   "source": [
    "### Model Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f0f3810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2_BIC(actions, rewards, condition):\n",
    "    \n",
    "    init_cond = np.array([np.random.randint(1,50)])    \n",
    "    bnds = [(1,50)] \n",
    "    km = len(bnds) # number of parameters fit in the model\n",
    "\n",
    "    optimum_output = minimize(m2_loglikelihood, init_cond, args=(r_alpha, p_alpha, actions, rewards, condition), method='L-BFGS-B', bounds=bnds)    \n",
    "    neg_loglikelihood = optimum_output.fun\n",
    "    \n",
    "    BIC = km * np.log(len(actions)) + 2*neg_loglikelihood\n",
    "    \n",
    "    return BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5855e98e",
   "metadata": {},
   "source": [
    "##### load model 1 functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "948cab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1_BIC(actions, rewards, condition):\n",
    "    \n",
    "    init_cond = [np.random.uniform(0,1)] # learning rate\n",
    "    bnds = [(1e-6,1)]\n",
    "    km = len(bnds) # number of parameters fit in the model\n",
    "    \n",
    "    optimum_output = minimize(m1_loglikelihood, init_cond, args=(beta, actions, rewards, condition), method='L-BFGS-B',bounds=bnds)    \n",
    "    neg_loglikelihood = optimum_output.fun\n",
    "    \n",
    "    BIC = km * np.log(len(actions)) + 2*neg_loglikelihood\n",
    "    return BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cc6fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m1_loglikelihood(alpha, beta, actions, reward, condition):\n",
    "    \n",
    "    q_value = np.ones((3,2))*0.0\n",
    "    T = len(actions)\n",
    "    L = 0  \n",
    "    \n",
    "    for t in range(T): # for every trial \n",
    "        \n",
    "        # compute choice probabilities of picking an action based on soft max \n",
    "        p = np.exp(beta * q_value[condition[t]-1,:]) / (np.exp(beta * q_value[condition[t]-1,:])).sum()\n",
    "\n",
    "        # compute choice probability for actual choice based on the probability computed above by condition \n",
    "        choiceProb = p[actions[t]-1]\n",
    " \n",
    "        # sum of the natural log of each individual choice probability to get the prob of a whole dataset (90 trials)\n",
    "        L += np.log(choiceProb) \n",
    "        \n",
    "        # update values with q learning, index for t and update by condition \n",
    "        if condition[t] == 1 or condition[t] == 2:\n",
    "            q_value[condition[t]-1, actions[t]-1] = q_value[condition[t]-1, actions[t]-1] + alpha * (reward[t] - q_value[condition[t]-1, actions[t]-1])\n",
    "\n",
    "    return -L   # this will return a negative log likelihood which is what we want to minimize to perform parameter recovery/fitting on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bd9e61",
   "metadata": {},
   "source": [
    "##### Perform recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d28d3da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is simulation number 1\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 32.99348781376011\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 28.336647294086212\n",
      "likelihood per trial: 0.7348051693306137\n",
      "done running this simulation\n",
      "this is simulation number 2\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 24.469260721856497\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7725020862164951\n",
      "done running this simulation\n",
      "this is simulation number 3\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 13.801778702367828\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 15.25485359121952\n",
      "likelihood per trial: 0.6930097072471654\n",
      "done running this simulation\n",
      "this is simulation number 4\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 28.88739040902474\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7153049603495163\n",
      "done running this simulation\n",
      "this is simulation number 5\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 26.90908881403869\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 35.840346398436594\n",
      "likelihood per trial: 0.7572049303287727\n",
      "done running this simulation\n",
      "this is simulation number 6\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 5.320065431353465\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 4.61738272717754\n",
      "likelihood per trial: 0.6186433079485726\n",
      "done running this simulation\n",
      "this is simulation number 7\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 3.708386254807635\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 2.934112481178282\n",
      "likelihood per trial: 0.5873503557160085\n",
      "done running this simulation\n",
      "this is simulation number 8\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 23.050690482070195\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7541448939054018\n",
      "done running this simulation\n",
      "this is simulation number 9\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 8.754654327206795\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 10.64170897223934\n",
      "likelihood per trial: 0.7061624481963241\n",
      "done running this simulation\n",
      "this is simulation number 10\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 35.85285479955191\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 26.88520026193487\n",
      "likelihood per trial: 0.7342305615328203\n",
      "done running this simulation\n",
      "this is simulation number 11\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 30.616865874063294\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 28.086951417470846\n",
      "likelihood per trial: 0.7385302547754165\n",
      "done running this simulation\n",
      "this is simulation number 12\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 36.17267754596985\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 49.18816288270502\n",
      "likelihood per trial: 0.7461331786987201\n",
      "done running this simulation\n",
      "this is simulation number 13\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 6.26782509857994\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 7.628569191130359\n",
      "likelihood per trial: 0.7197810844371781\n",
      "done running this simulation\n",
      "this is simulation number 14\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 38.35843069134658\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7354766076617764\n",
      "done running this simulation\n",
      "this is simulation number 15\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 30.588668521488\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7554937017788868\n",
      "done running this simulation\n",
      "this is simulation number 16\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 39.211233196204866\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.751821671208224\n",
      "done running this simulation\n",
      "this is simulation number 17\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 9.58631120116102\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 10.328334347588399\n",
      "likelihood per trial: 0.7312012630739867\n",
      "done running this simulation\n",
      "this is simulation number 18\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 9.907561314212968\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 12.548267031151402\n",
      "likelihood per trial: 0.7224252605793247\n",
      "done running this simulation\n",
      "this is simulation number 19\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 49.66566104769927\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 34.06117886923742\n",
      "likelihood per trial: 0.7160197580126352\n",
      "done running this simulation\n",
      "this is simulation number 20\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 48.17621761821951\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7485886403529027\n",
      "done running this simulation\n",
      "this is simulation number 21\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 34.88537937787808\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 16.720812293160087\n",
      "likelihood per trial: 0.7380577754205249\n",
      "done running this simulation\n",
      "this is simulation number 22\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 4.602768984094798\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 5.250935210200848\n",
      "likelihood per trial: 0.6270308870098708\n",
      "done running this simulation\n",
      "this is simulation number 23\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 43.49432104206554\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7371120833021648\n",
      "done running this simulation\n",
      "this is simulation number 24\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 41.33437846980221\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.774183581017007\n",
      "done running this simulation\n",
      "this is simulation number 25\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 39.78190149563934\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7510163350056208\n",
      "done running this simulation\n",
      "this is simulation number 26\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 21.847790598302666\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 47.41769367166705\n",
      "likelihood per trial: 0.7494028946511478\n",
      "done running this simulation\n",
      "this is simulation number 27\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 17.38740184647066\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 23.136551553809102\n",
      "likelihood per trial: 0.7304444843430947\n",
      "done running this simulation\n",
      "this is simulation number 28\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 2.251649868378732\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 2.388800567374087\n",
      "likelihood per trial: 0.5552658523524767\n",
      "done running this simulation\n",
      "this is simulation number 29\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 31.63501630905299\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7625074913169289\n",
      "done running this simulation\n",
      "this is simulation number 30\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 32.01549456352233\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 18.2444910891635\n",
      "likelihood per trial: 0.7167698707337607\n",
      "done running this simulation\n",
      "this is simulation number 31\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 21.310655562736507\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 16.810157524172077\n",
      "likelihood per trial: 0.7250846871188662\n",
      "done running this simulation\n",
      "this is simulation number 32\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 46.43371954622829\n",
      "best action = 1\n",
      "Checking simulated dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit beta 50.0\n",
      "likelihood per trial: 0.7651105400345494\n",
      "done running this simulation\n",
      "this is simulation number 33\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 27.34192734802015\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 38.560907489112196\n",
      "likelihood per trial: 0.7552125053464975\n",
      "done running this simulation\n",
      "this is simulation number 34\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 30.493666690544796\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 20.2131937890616\n",
      "likelihood per trial: 0.7455748878906555\n",
      "done running this simulation\n",
      "this is simulation number 35\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 15.130727463384739\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 11.36615329713124\n",
      "likelihood per trial: 0.6945087317833368\n",
      "done running this simulation\n",
      "this is simulation number 36\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 1.6410928188293874\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 1.798729636530785\n",
      "likelihood per trial: 0.5327266288779077\n",
      "done running this simulation\n",
      "this is simulation number 37\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 22.671689852426894\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 33.18156090943327\n",
      "likelihood per trial: 0.7397460208459948\n",
      "done running this simulation\n",
      "this is simulation number 38\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 43.02901742629486\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 39.81903722952821\n",
      "likelihood per trial: 0.7352067545128503\n",
      "done running this simulation\n",
      "this is simulation number 39\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 18.672118117546894\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 12.817339979215093\n",
      "likelihood per trial: 0.7003418422201118\n",
      "done running this simulation\n",
      "this is simulation number 40\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 13.256902478385765\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 12.528251438310823\n",
      "likelihood per trial: 0.690251463917626\n",
      "done running this simulation\n",
      "this is simulation number 41\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 42.30070819845837\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 21.373985561328574\n",
      "likelihood per trial: 0.7451990234606662\n",
      "done running this simulation\n",
      "this is simulation number 42\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 12.687954670961293\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 9.908609293139646\n",
      "likelihood per trial: 0.7010690084322497\n",
      "done running this simulation\n",
      "this is simulation number 43\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 8.058673381730129\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 9.970748931789393\n",
      "likelihood per trial: 0.6638866406423231\n",
      "done running this simulation\n",
      "this is simulation number 44\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 43.33109653497214\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7722024232023165\n",
      "done running this simulation\n",
      "this is simulation number 45\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 18.882258416558198\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7703523556025993\n",
      "done running this simulation\n",
      "this is simulation number 46\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 2.2933561800198445\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 2.16069919721791\n",
      "likelihood per trial: 0.5573824396048832\n",
      "done running this simulation\n",
      "this is simulation number 47\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 26.942087224561426\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 19.909198795074367\n",
      "likelihood per trial: 0.7100882960654737\n",
      "done running this simulation\n",
      "this is simulation number 48\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 45.45952351047242\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 23.225775395869153\n",
      "likelihood per trial: 0.7217676646458083\n",
      "done running this simulation\n",
      "this is simulation number 49\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 25.947869552935924\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7557095414866837\n",
      "done running this simulation\n",
      "this is simulation number 50\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 29.758182526231693\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 16.49173424725629\n",
      "likelihood per trial: 0.7175620502863818\n",
      "done running this simulation\n",
      "this is simulation number 51\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 48.61110070310081\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7488154137113254\n",
      "done running this simulation\n",
      "this is simulation number 52\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 16.34639304963514\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.757102368416511\n",
      "done running this simulation\n",
      "this is simulation number 53\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 9.539887885513707\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 11.678080598015322\n",
      "likelihood per trial: 0.709057018455684\n",
      "done running this simulation\n",
      "this is simulation number 54\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 26.128152922712868\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 20.752183764376376\n",
      "likelihood per trial: 0.7297077201561317\n",
      "done running this simulation\n",
      "this is simulation number 55\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 35.923284223225735\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 49.305645099319655\n",
      "likelihood per trial: 0.7375016972962432\n",
      "done running this simulation\n",
      "this is simulation number 56\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 32.40913398731479\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7507933462910512\n",
      "done running this simulation\n",
      "this is simulation number 57\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 20.340638203910267\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 44.41692900269474\n",
      "likelihood per trial: 0.753832486549653\n",
      "done running this simulation\n",
      "this is simulation number 58\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 16.884498232439636\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 9.840437657845184\n",
      "likelihood per trial: 0.701753634084408\n",
      "done running this simulation\n",
      "this is simulation number 59\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 15.922063145456864\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 24.909384026027833\n",
      "likelihood per trial: 0.7389178645610642\n",
      "done running this simulation\n",
      "this is simulation number 60\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 18.709685006152252\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 13.09858991468967\n",
      "likelihood per trial: 0.6969500279881967\n",
      "done running this simulation\n",
      "this is simulation number 61\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 11.436241397050656\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 12.186429101224608\n",
      "likelihood per trial: 0.6954581672376702\n",
      "done running this simulation\n",
      "this is simulation number 62\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 36.4881448711503\n",
      "best action = 1\n",
      "Checking simulated dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit beta 30.596010624283473\n",
      "likelihood per trial: 0.7422652692114536\n",
      "done running this simulation\n",
      "this is simulation number 63\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 15.95801342351609\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 12.022390790461708\n",
      "likelihood per trial: 0.7209020034067578\n",
      "done running this simulation\n",
      "this is simulation number 64\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 37.99144763036685\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7603643758830124\n",
      "done running this simulation\n",
      "this is simulation number 65\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 22.02066519604999\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 19.696481010774043\n",
      "likelihood per trial: 0.7137941887887366\n",
      "done running this simulation\n",
      "this is simulation number 66\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 4.50538767580121\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 5.196230653979897\n",
      "likelihood per trial: 0.652919650212068\n",
      "done running this simulation\n",
      "this is simulation number 67\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 28.74684526557709\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 26.013439349565726\n",
      "likelihood per trial: 0.7142065210423989\n",
      "done running this simulation\n",
      "this is simulation number 68\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 8.607012503537929\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 10.508637037970024\n",
      "likelihood per trial: 0.6931823051744737\n",
      "done running this simulation\n",
      "this is simulation number 69\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 4.2398263473137074\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 7.557959823844751\n",
      "likelihood per trial: 0.6152920372709858\n",
      "done running this simulation\n",
      "this is simulation number 70\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 37.15300618058625\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 37.83186399032755\n",
      "likelihood per trial: 0.7383053188344141\n",
      "done running this simulation\n",
      "this is simulation number 71\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 1.5542282549682676\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 2.4501332001846237\n",
      "likelihood per trial: 0.5704226804794977\n",
      "done running this simulation\n",
      "this is simulation number 72\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 38.28488473051457\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 21.12783294753451\n",
      "likelihood per trial: 0.7516374335014362\n",
      "done running this simulation\n",
      "this is simulation number 73\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 23.594660170098773\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 25.006363633602426\n",
      "likelihood per trial: 0.7538127520332064\n",
      "done running this simulation\n",
      "this is simulation number 74\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 4.512911899606395\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 4.349097130619689\n",
      "likelihood per trial: 0.6298039831552915\n",
      "done running this simulation\n",
      "this is simulation number 75\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 3.7384259273297737\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 4.20453128998046\n",
      "likelihood per trial: 0.5811424879501855\n",
      "done running this simulation\n",
      "this is simulation number 76\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 31.049783336428153\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 21.719436202461004\n",
      "likelihood per trial: 0.7400021359159219\n",
      "done running this simulation\n",
      "this is simulation number 77\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 44.51000926407489\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.774231314720846\n",
      "done running this simulation\n",
      "this is simulation number 78\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 5.324355152923078\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 4.23806878128246\n",
      "likelihood per trial: 0.5994122693366982\n",
      "done running this simulation\n",
      "this is simulation number 79\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 10.877037077657402\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7693879997943862\n",
      "done running this simulation\n",
      "this is simulation number 80\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 8.696025112485842\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 9.334760956879506\n",
      "likelihood per trial: 0.6806142554781632\n",
      "done running this simulation\n",
      "this is simulation number 81\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 5.33135673049641\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 7.234090153359326\n",
      "likelihood per trial: 0.6572342861528997\n",
      "done running this simulation\n",
      "this is simulation number 82\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 45.06029475309983\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7444859401347019\n",
      "done running this simulation\n",
      "this is simulation number 83\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 14.41872149108754\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 13.188892267787717\n",
      "likelihood per trial: 0.7355811973289809\n",
      "done running this simulation\n",
      "this is simulation number 84\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 26.85191551192945\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 18.050559009469872\n",
      "likelihood per trial: 0.7316675289011532\n",
      "done running this simulation\n",
      "this is simulation number 85\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 12.27968925534052\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 18.096234024284442\n",
      "likelihood per trial: 0.6936610344994795\n",
      "done running this simulation\n",
      "this is simulation number 86\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 11.195135698950345\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 23.187882472669692\n",
      "likelihood per trial: 0.7288944323963772\n",
      "done running this simulation\n",
      "this is simulation number 87\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 18.454351035238343\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 13.233752880508439\n",
      "likelihood per trial: 0.6592495802592574\n",
      "done running this simulation\n",
      "this is simulation number 88\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 14.274072609164941\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 14.13911404921539\n",
      "likelihood per trial: 0.689264947906014\n",
      "done running this simulation\n",
      "this is simulation number 89\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 40.396325285621884\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 20.58954818832297\n",
      "likelihood per trial: 0.7390058667867155\n",
      "done running this simulation\n",
      "this is simulation number 90\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 19.25095135357987\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 22.04645062043632\n",
      "likelihood per trial: 0.7301355081505958\n",
      "done running this simulation\n",
      "this is simulation number 91\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 38.15644578635959\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7534965264677229\n",
      "done running this simulation\n",
      "this is simulation number 92\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 23.219830211641344\n",
      "best action = 1\n",
      "Checking simulated dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit beta 30.499366513745418\n",
      "likelihood per trial: 0.7116043571847328\n",
      "done running this simulation\n",
      "this is simulation number 93\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 28.03676334673855\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 38.817365232383935\n",
      "likelihood per trial: 0.7438589315081336\n",
      "done running this simulation\n",
      "this is simulation number 94\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 14.728676748224455\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 15.007667038668982\n",
      "likelihood per trial: 0.7016030392858505\n",
      "done running this simulation\n",
      "this is simulation number 95\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 49.93509571772768\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7583935964280676\n",
      "done running this simulation\n",
      "this is simulation number 96\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 40.10538576902065\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 50.0\n",
      "likelihood per trial: 0.7427381161728842\n",
      "done running this simulation\n",
      "this is simulation number 97\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 1.5409033406420791\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 1.0\n",
      "likelihood per trial: 0.5143083667829047\n",
      "done running this simulation\n",
      "this is simulation number 98\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 24.220848559655572\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 25.046348982491274\n",
      "likelihood per trial: 0.7233962115902574\n",
      "done running this simulation\n",
      "this is simulation number 99\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 24.32635842587169\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 32.52069776426598\n",
      "likelihood per trial: 0.6853631443655794\n",
      "done running this simulation\n",
      "this is simulation number 100\n",
      "r_alpha for this simulation is: 0.43\n",
      "p_alpha for this simulation is, 0.21\n",
      "beta for this simulation is, 28.69789464699339\n",
      "best action = 1\n",
      "Checking simulated dataset...\n",
      "fit beta 21.23756698205604\n",
      "likelihood per trial: 0.7276047322431204\n",
      "done running this simulation\n"
     ]
    }
   ],
   "source": [
    "# define parameters \n",
    "r_p = np.full((3, 8), 1, dtype=int)\n",
    "r_p = np.append(r_p, [0, 0, 0, 0, 0, 0])\n",
    "r_p = np.random.permutation(r_p)\n",
    "\n",
    "p_p = np.full((3, 8), 0, dtype=int)\n",
    "p_p = np.append(p_p, [-1, -1, -1, -1, -1, -1])\n",
    "p_p = np.random.permutation(p_p)\n",
    "\n",
    "inv_rp = np.full((24), 0, dtype=int)\n",
    "inv_rp = np.append(inv_rp, [1, 1, 1, 1, 1, 1])\n",
    "inv_rp= np.random.permutation(inv_rp)\n",
    "\n",
    "inv_pp = np.full((24), -1, dtype=int)\n",
    "inv_pp = np.append(inv_pp, [0, 0, 0, 0, 0, 0])\n",
    "inv_pp = np.random.permutation(inv_pp)\n",
    "\n",
    "n_timesteps = 3 # define how many times to loop through-- default to 3\n",
    "n_trials_per_block = 30 # default to 30\n",
    "\n",
    "best_action = np.random.choice(2) + 1   # action 1 or 2\n",
    "\n",
    "### Initialize output list to simulate through different values of alpha\n",
    "D = []\n",
    "\n",
    "for i in np.arange(1,101): # number of simulations to run \n",
    "    print('this is simulation number ' + str(i))\n",
    "\n",
    "    r_alpha = 0.43\n",
    "    p_alpha = 0.21\n",
    "    print('r_alpha for this simulation is: ' + str(r_alpha))\n",
    "    print('p_alpha for this simulation is, ' + str(p_alpha))\n",
    "   \n",
    "    for beta in np.random.uniform(1,50,1):  \n",
    "        print('beta for this simulation is, ' + str(beta))\n",
    "                    \n",
    "        print('best action = ' + str(best_action))\n",
    "\n",
    "        for i in np.arange(n_timesteps):\n",
    "\n",
    "            params = {\n",
    "            'n_actions' : 2,\n",
    "            'r_p': r_p,\n",
    "            'p_p': p_p,\n",
    "            'inv_rp': inv_rp,\n",
    "            'inv_pp': inv_pp,\n",
    "            'best_action' : best_action,\n",
    "            'r_alpha' : r_alpha,\n",
    "            'p_alpha' : p_alpha, \n",
    "            'beta' : beta  \n",
    "            }\n",
    "\n",
    "        ### First, simulate with fixed parameter value. \n",
    "        _, _, sim_output = RP_simulation(n_timesteps, n_trials_per_block, params) # this returns actions, rewards, conditon, & optimal action cols\n",
    "\n",
    "        # Convert to dataframe and append alpha, beta, rewards, & optimal action    \n",
    "        d=pd.DataFrame(sim_output['actions'], columns = ['actions'])\n",
    "        d.insert(1, 'r_alpha', r_alpha),\n",
    "        d.insert(2, 'p_alpha', p_alpha),\n",
    "        d.insert(3, 'beta', beta),\n",
    "        d.insert(4, 'rewards', sim_output['rewards']),\n",
    "        d.insert(5, 'condition', sim_output['condition'])\n",
    "        d.insert(6, 'optimal_action', sim_output['optimal_action']),\n",
    "        d.insert(7, 'best_action', best_action)\n",
    "\n",
    "        ### Then, fit simulated dataset to recover parameters. \n",
    "        \n",
    "        ### PARAMETER RECOVERY\n",
    "        \n",
    "        print('Checking simulated dataset...')\n",
    "        \n",
    "        #  Obtain Log Likelihood function parameters (alpha, actions, rewards) using d   \n",
    "        r_alpha = d[\"r_alpha\"].iloc[0]\n",
    "    \n",
    "        p_alpha = d[\"p_alpha\"].iloc[0]\n",
    "        \n",
    "        sim_beta = d[\"beta\"].iloc[0]\n",
    "        \n",
    "        actions = d['actions']\n",
    "        \n",
    "        rewards = d['rewards'].values\n",
    "    \n",
    "        condition = d[\"condition\"].values\n",
    "                \n",
    "        ### Then, compute best fit alpha which comes from fitting function and is fit_alpha.x[0]\n",
    "        \n",
    "        res = fit_RP_Learning(r_alpha, p_alpha, actions, rewards, condition) # optimizer to return optimal outputs\n",
    "\n",
    "        fit_beta = res.x[0]\n",
    "        print('fit beta ' + str(fit_beta))\n",
    "\n",
    "        ### max LL gets computed with best fit parameters; alpha = fit_alpha.x[0]        \n",
    "\n",
    "        max_LL = m2_loglikelihood(fit_beta, r_alpha, p_alpha, actions, rewards, condition) # this is already returned as a negative in my fx\n",
    "    \n",
    "        LL_per_trial = np.exp(-max_LL/len(actions))\n",
    "        print('likelihood per trial: ' + str(LL_per_trial))\n",
    "\n",
    "        print('done running this simulation')\n",
    "        \n",
    "#         BIC_model1 = model1_BIC(actions, rewards, condition) \n",
    "        BIC_model2 = model2_BIC(actions, rewards, condition)\n",
    "\n",
    "        d.insert(8, 'log_likelihood', -max_LL),\n",
    "        d.insert(9, 'fit_beta', res.x[0]),\n",
    "        d.insert(10, 'LL_per_trial', LL_per_trial)\n",
    "#         d.insert(11, 'model1_BIC', BIC_model1)\n",
    "        d.insert(11, 'model2_BIC', BIC_model2)\n",
    "\n",
    "\n",
    "        D.append(d)\n",
    "\n",
    "        data = pd.concat(D, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9637fe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actions</th>\n",
       "      <th>r_alpha</th>\n",
       "      <th>p_alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>rewards</th>\n",
       "      <th>condition</th>\n",
       "      <th>optimal_action</th>\n",
       "      <th>best_action</th>\n",
       "      <th>log_likelihood</th>\n",
       "      <th>fit_beta</th>\n",
       "      <th>LL_per_trial</th>\n",
       "      <th>model2_BIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>32.993488</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-27.73349</td>\n",
       "      <td>28.336647</td>\n",
       "      <td>0.734805</td>\n",
       "      <td>59.966790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>32.993488</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-27.73349</td>\n",
       "      <td>28.336647</td>\n",
       "      <td>0.734805</td>\n",
       "      <td>59.966790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>32.993488</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-27.73349</td>\n",
       "      <td>28.336647</td>\n",
       "      <td>0.734805</td>\n",
       "      <td>59.966790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>32.993488</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-27.73349</td>\n",
       "      <td>28.336647</td>\n",
       "      <td>0.734805</td>\n",
       "      <td>59.966790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>32.993488</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-27.73349</td>\n",
       "      <td>28.336647</td>\n",
       "      <td>0.734805</td>\n",
       "      <td>59.966790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>2</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>28.697895</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-28.61976</td>\n",
       "      <td>21.237567</td>\n",
       "      <td>0.727605</td>\n",
       "      <td>61.739329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>1</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>28.697895</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-28.61976</td>\n",
       "      <td>21.237567</td>\n",
       "      <td>0.727605</td>\n",
       "      <td>61.739329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>1</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>28.697895</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-28.61976</td>\n",
       "      <td>21.237567</td>\n",
       "      <td>0.727605</td>\n",
       "      <td>61.739329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>1</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>28.697895</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-28.61976</td>\n",
       "      <td>21.237567</td>\n",
       "      <td>0.727605</td>\n",
       "      <td>61.739329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>1</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>28.697895</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-28.61976</td>\n",
       "      <td>21.237567</td>\n",
       "      <td>0.727605</td>\n",
       "      <td>61.739329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      actions  r_alpha  p_alpha       beta  rewards  condition  \\\n",
       "0           2     0.43     0.21  32.993488       -1          2   \n",
       "1           1     0.43     0.21  32.993488        0          2   \n",
       "2           2     0.43     0.21  32.993488        0          3   \n",
       "3           1     0.43     0.21  32.993488        1          1   \n",
       "4           1     0.43     0.21  32.993488        1          1   \n",
       "...       ...      ...      ...        ...      ...        ...   \n",
       "8995        2     0.43     0.21  28.697895        0          3   \n",
       "8996        1     0.43     0.21  28.697895        0          2   \n",
       "8997        1     0.43     0.21  28.697895        0          2   \n",
       "8998        1     0.43     0.21  28.697895        0          3   \n",
       "8999        1     0.43     0.21  28.697895        1          1   \n",
       "\n",
       "      optimal_action  best_action  log_likelihood   fit_beta  LL_per_trial  \\\n",
       "0                  0            1       -27.73349  28.336647      0.734805   \n",
       "1                  1            1       -27.73349  28.336647      0.734805   \n",
       "2                  3            1       -27.73349  28.336647      0.734805   \n",
       "3                  1            1       -27.73349  28.336647      0.734805   \n",
       "4                  1            1       -27.73349  28.336647      0.734805   \n",
       "...              ...          ...             ...        ...           ...   \n",
       "8995               3            1       -28.61976  21.237567      0.727605   \n",
       "8996               1            1       -28.61976  21.237567      0.727605   \n",
       "8997               1            1       -28.61976  21.237567      0.727605   \n",
       "8998               3            1       -28.61976  21.237567      0.727605   \n",
       "8999               1            1       -28.61976  21.237567      0.727605   \n",
       "\n",
       "      model2_BIC  \n",
       "0      59.966790  \n",
       "1      59.966790  \n",
       "2      59.966790  \n",
       "3      59.966790  \n",
       "4      59.966790  \n",
       "...          ...  \n",
       "8995   61.739329  \n",
       "8996   61.739329  \n",
       "8997   61.739329  \n",
       "8998   61.739329  \n",
       "8999   61.739329  \n",
       "\n",
       "[9000 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6fd2ce",
   "metadata": {},
   "source": [
    "### visualizing parameter recovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8495231",
   "metadata": {},
   "source": [
    "#### reward alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3e9b925",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7032607434355458"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = ( 10 , 5 ))\n",
    "\n",
    "figure = sns.scatterplot(ax = ax, x = \"r_alpha\", y = \"fit_r_alpha\",\n",
    "                data = data, color = \"c\")\n",
    "\n",
    "# Set label for x-axis\n",
    "ax.set_xlabel( \"Simulated Reward Alpha \" + \"(p_alpha= \" + str(p_alpha) + \")\" , size = 15 )\n",
    "  \n",
    "# Set label for y-axis\n",
    "ax.set_ylabel( \"Fit Reward Alpha\" , size = 15 )\n",
    "  \n",
    "# Set title for plot\n",
    "ax.set_title( \"Model 2 Simulations\" , size = 20 )\n",
    "  \n",
    "# Display figure\n",
    "#plt.plot([1, 0], [1, 0], linewidth=2)\n",
    "plt.show()\n",
    "data['r_alpha'].corr(data['fit_r_alpha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2a463b",
   "metadata": {},
   "source": [
    "#### punishment alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6c6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = ( 10 , 5 ))\n",
    "\n",
    "figure = sns.scatterplot(ax = ax, x = \"p_alpha\", y = \"fit_p_alpha\",\n",
    "                data = data, color = \"c\")\n",
    "\n",
    "# Set label for x-axis\n",
    "ax.set_xlabel( \"Simulated Punishment Alpha \" + \"(r_alpha= \" + str(r_alpha) + \")\" , size = 15 )\n",
    "  \n",
    "# Set label for y-axis\n",
    "ax.set_ylabel( \"Fit Puishment Alpha\" , size = 15 )\n",
    "  \n",
    "# Set title for plot\n",
    "ax.set_title( \"Model 2 Simulations\" , size = 20 )\n",
    "  \n",
    "# Display figure\n",
    "#plt.plot([1, 0], [1, 0], linewidth=2)\n",
    "plt.show()\n",
    "data['p_alpha'].corr(data['fit_p_alpha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cec834",
   "metadata": {},
   "source": [
    "#### beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80d26cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7468145061886609"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = ( 10 , 5 ))\n",
    "\n",
    "figure = sns.scatterplot(ax = ax, x = \"beta\", y = \"fit_beta\",\n",
    "                data = data, color = \"c\")\n",
    "\n",
    "# Set label for x-axis\n",
    "ax.set_xlabel( \"Simulated Beta \" + \"(r_alpha= \" + str(r_alpha) + \")\" + \"(p_alpha= \" + str(p_alpha) + \")\" ,  size = 15 )\n",
    "  \n",
    "# Set label for y-axis\n",
    "ax.set_ylabel( \"Fit Beta\" , size = 15 )\n",
    "  \n",
    "# Set title for plot\n",
    "ax.set_title( \"Model 2 Simulations\" , size = 20 )\n",
    "  \n",
    "# Display figure\n",
    "#plt.plot([1, 0], [1, 0], linewidth=2)\n",
    "plt.show()\n",
    "data['beta'].corr(data['fit_beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea5d4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
